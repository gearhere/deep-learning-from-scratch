{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Perceptron\" data-toc-modified-id=\"Perceptron-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Perceptron</a></span><ul class=\"toc-item\"><li><span><a href=\"#Concepts\" data-toc-modified-id=\"Concepts-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Concepts</a></span></li><li><span><a href=\"#Simple-Logic-Circuit\" data-toc-modified-id=\"Simple-Logic-Circuit-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Simple Logic Circuit</a></span></li><li><span><a href=\"#Realization-of-Perceptron\" data-toc-modified-id=\"Realization-of-Perceptron-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Realization of Perceptron</a></span></li><li><span><a href=\"#Limitation-(XOR-gate)\" data-toc-modified-id=\"Limitation-(XOR-gate)-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Limitation (XOR gate)</a></span><ul class=\"toc-item\"><li><span><a href=\"#XOR-gate的应用\" data-toc-modified-id=\"XOR-gate的应用-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>XOR gate的应用</a></span></li></ul></li><li><span><a href=\"#MLP（Multi-Layered-Perceptron）\" data-toc-modified-id=\"MLP（Multi-Layered-Perceptron）-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>MLP（Multi-Layered Perceptron）</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combination-of-Gates\" data-toc-modified-id=\"Combination-of-Gates-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Combination of Gates</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Frank Ronsenblatt 1957\n",
    "- Origin of neural network(deep learning)\n",
    "- Multiple inputs, one output\n",
    "- two signals: 1/0\n",
    "\n",
    "严格来说，本章讨论的是“人工神经元”/“朴素感知机”\n",
    "> 决定感知机参数的并不是计算机，而是我们人。我们看着真值表这种“训练数据”，人工考虑（想到了）参数的值。而机器学习的课题就是将这个决定参数值的工作交由计算机自动进行。**学习**是确定合适的参数的过程，而人要做的是思考感知机的构造（模型），并把训练数据交给计算机。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**神经元/节点（node）**\n",
    "\n",
    "**权重（weight）**\n",
    "\n",
    "**阈值**\n",
    "\n",
    "**激活**\n",
    "\n",
    "**偏置**\n",
    "\n",
    "\\begin{equation}\n",
    "y =\\left\\{\n",
    "\\begin{aligned}\n",
    "0 \\ (w_{1}x_{1} + w_{2}x_{2} \\le \\theta) \\\\\n",
    "1 \\ (w_{1}x_{1} + w_{2}x_{2} > \\theta) \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\n",
    "</br>\n",
    "\n",
    "<center>添加偏置b</center>\n",
    "\n",
    "</br>\n",
    "\n",
    "\\begin{equation}\n",
    "y =\\left\\{\n",
    "\\begin{aligned}\n",
    "0 \\ (w_{1}x_{1} + w_{2}x_{2} + b \\le 0) \\\\\n",
    "1 \\ (w_{1}x_{1} + w_{2}x_{2} + b > 0) \\\\\n",
    "\\end{aligned}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    ">w1,w2是控制输入信号的**重要性**的参数，而偏置b是调整神经元被**激活的容易程度**的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Logic Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AND gate\n",
    "- NAND gate\n",
    "- OR gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realization of Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AND(x1, x2):\n",
    "    w1, w2, theta = 0.5, 0.5, 0.7\n",
    "    tmp = x1 * w1 + x2 * w2\n",
    "    if tmp <= theta:\n",
    "        return 0\n",
    "    elif tmp > theta:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(AND(0,0))\n",
    "print(AND(0,1))\n",
    "print(AND(1,0))\n",
    "print(AND(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入权重和偏置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.19999999999999996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([0, 1])       # 输入\n",
    "w = np.array([0.5, 0.5])   # 权重\n",
    "b = -0.7                   # 偏置\n",
    "print(np.sum(w*x) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# AND gate\n",
    "def AND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5 ,0.5])\n",
    "    b = -0.7\n",
    "    tmp = np.sum(x*w) + b\n",
    "    if tmp <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "print(AND(0, 0))\n",
    "print(AND(0, 1))\n",
    "print(AND(1, 0))\n",
    "print(AND(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# NAND gate\n",
    "def NAND(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5]) # 方法二：把权重、偏置都加上负号，原本的if-else条件不变\n",
    "    b = -0.7\n",
    "    tmp = np.sum(x*w) + b\n",
    "    if tmp <= 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "print(NAND(0, 0))\n",
    "print(NAND(0, 1))\n",
    "print(NAND(1, 0))\n",
    "print(NAND(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# OR gate\n",
    "def OR(x1, x2):\n",
    "    x = np.array([x1, x2])\n",
    "    w = np.array([0.5, 0.5])\n",
    "    b = -0.5\n",
    "    tmp = np.sum(x*w) + b\n",
    "    if tmp < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "print(OR(0, 0))\n",
    "print(OR(0, 1))\n",
    "print(OR(1, 0))\n",
    "print(OR(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation (XOR gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 仅当x1或x2中的一方为1时，才会输出1（exclusive OR）。\n",
    "\n",
    "|x1|x2|y|\n",
    "|--|--|--|\n",
    "|0|0|0|\n",
    "|1|0|1|\n",
    "|0|1|1|\n",
    "|1|1|0|\n",
    "\n",
    "\n",
    "帮助理解“异或”的概念：\n",
    "\n",
    "> 男性和女性能生出孩子，否则就不行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR gate的应用\n",
    "\n",
    "https://zhuanlan.zhihu.com/p/43826007\n",
    "\n",
    "- 交换两个数：\n",
    "\n",
    "有两个数A=a和B=b，不依靠第三个变量交换它们:\n",
    "\n",
    "a⊕b⊕a\n",
    "\n",
    "- 只出现一次的数字\n",
    "\n",
    "给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素：\n",
    "\n",
    "- 寻找重复数\n",
    "\n",
    "给定一个包含 n + 1 个整数的数组 nums，其数字都在 1 到 n 之间（包括 1 和 n），可知至少存在一个重复的整数。假设只有一个重复的整数，找出这个重复的数。\n",
    "\n",
    "- 找不同\n",
    "\n",
    "给定两个字符串 s 和 t，它们只包含小写字母。字符串 t 由字符串 s 随机重排，然后在随机位置添加一个字母。请找出在 t 中被添加的字母。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为什么单层感知机无法实现异或门/分离非线性空间？** （可以通过几何表示理解）\n",
    "\n",
    "感知机只能表示**线性空间**（由直线分割而成的空间）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP（Multi-Layered Perceptron）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination of Gates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两层感知机（因为拥有权重的层实质上只有两层）：\n",
    "\n",
    "XOR = NAND + OR → AND\n",
    "\n",
    "|x1|x2|s1|s2|y|\n",
    "|-|-|-|-|-|\n",
    "|0|0|1|0|0|\n",
    "|1|0|1|1|1|\n",
    "|0|1|1|1|1|\n",
    "|1|1|0|1|0|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "第零层：x1, x2\n",
    "第一层：s1, s2\n",
    "第二层：y\n",
    "'''\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    s1 = NAND(x1, x2)\n",
    "    s2 = OR(x1, x2)\n",
    "    y = AND(s1, s2)\n",
    "    return y\n",
    "\n",
    "print(XOR(0, 0))\n",
    "print(XOR(0, 1))\n",
    "print(XOR(1, 0))\n",
    "print(XOR(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法器，二进制转换为十进制的编码器，甚至计算机都可以用感知机表示（《计算机系统要素：从零开始构建现代计算机》）；\n",
    "\n",
    "理论上，激活函数使用了非线性的**sigmoid**函数的感知机，可以表示任何函数。\n",
    "\n",
    "> 实际上,在用与非门等低层的元件构建计算机的情况下，分阶段地制作所需的零件（模块）会比较自然，即先实现与门和或门，然后实现半加器和全加器，接着实现算数逻辑单元（ALU），然后实现CPU。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
